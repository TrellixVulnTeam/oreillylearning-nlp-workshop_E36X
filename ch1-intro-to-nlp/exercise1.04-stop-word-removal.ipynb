{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfe395b9-1558-4c62-835e-709942cbfcd7",
   "metadata": {},
   "source": [
    "### Exercise 1.04: Stop Word Removal\n",
    "In this exercise, we will check the list of stop words provided by the nltk library. Based on this list, we will filter out the stop words included in our text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a700d8df-a804-4866-bf3e-5472c4e4349f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/LNonyane/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk import download\n",
    "download('stopwords')\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cad868a6-7c92-4ba2-ac3e-0468b96ef53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# English stopwords\n",
    "stop_words = stopwords.words('english') # arabic, danish, dutch, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c25edcf-f045-49cd-a890-3687a6dcab91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20ebce1c-031e-4ec9-bbcf-66bcd2b48cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'I am learning Python. It is one of the most popular programming languages'\n",
    "sentence_words = word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13922cda-fc1d-4341-bc74-4056fe0ce202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'learning', 'Python', '.', 'It', 'is', 'one', 'of', 'the', 'most', 'popular', 'programming', 'languages']\n"
     ]
    }
   ],
   "source": [
    "# print list of tokens\n",
    "print(sentence_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "105506b1-a286-43fd-bc4e-be7e5e241c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words\n",
    "def remove_stop_words(sentence_words, stop_words):\n",
    "    return ' '.join([word for word in sentence_words if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1144c1b-5ce1-4bf2-942a-6f9e2a38f8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I learning Python . It one popular programming languages\n"
     ]
    }
   ],
   "source": [
    "sentence_no_stops = remove_stop_words(sentence_words, stop_words)\n",
    "print(sentence_no_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8165fc93-83b2-42a5-be37-d10560a139d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning Python . popular programming languages\n"
     ]
    }
   ],
   "source": [
    "# Add custom stop word\n",
    "stop_words.extend(['I', 'It', 'one'])\n",
    "print(remove_stop_words(sentence_words, stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd67b00-bb24-4797-b3e7-619dc9935e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
