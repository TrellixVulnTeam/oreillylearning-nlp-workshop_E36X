{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9659dd3c-46c8-4417-97d1-98b2b255a121",
   "metadata": {
    "tags": []
   },
   "source": [
    "## AI Capstone - Luke J Nonyane"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5d9078-4213-49d8-ae0f-e11e97d68dc1",
   "metadata": {},
   "source": [
    "### DESCRIPTION\n",
    "Problem Statement\n",
    "•\tAmazon is an online shopping website that now caters to millions of people everywhere. Over 34,000 consumer reviews for Amazon brand products like Kindle, Fire TV Stick and more are provided. \n",
    "•\tThe dataset has attributes like brand, categories, primary categories, reviews.title, reviews.text, and the sentiment. Sentiment is a categorical variable with three levels \"Positive\", \"Negative“, and \"Neutral\". For a given unseen data, the sentiment needs to be predicted.\n",
    "•\tYou are required to predict Sentiment or Satisfaction of a purchase based on multiple features and review text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f63f7d-4237-4162-a3ea-9f2100675121",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Project Task: Week 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90094ee2-7651-4a5f-ad3e-2542e9a9e598",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### EDA - Class Imbalance Problem\n",
    "•\tSee what a positive, negative, and neutral review looks like\n",
    "\n",
    "•\tCheck the class count for each class. It’s a class imbalance problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c59469d-6742-47ca-868b-d3049191411a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 8) (1000, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>primaryCategories</th>\n",
       "      <th>reviews.date</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.title</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All-New Fire HD 8 Tablet, 8\" HD Display, Wi-Fi...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>2016-12-26T00:00:00.000Z</td>\n",
       "      <td>Purchased on Black FridayPros - Great Price (e...</td>\n",
       "      <td>Powerful tablet</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon - Echo Plus w/ Built-In Hub - Silver</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Amazon Echo,Smart Home,Networking,Home &amp; Tools...</td>\n",
       "      <td>Electronics,Hardware</td>\n",
       "      <td>2018-01-17T00:00:00.000Z</td>\n",
       "      <td>I purchased two Amazon in Echo Plus and two do...</td>\n",
       "      <td>Amazon Echo Plus AWESOME</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon Echo Show Alexa-enabled Bluetooth Speak...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Amazon Echo,Virtual Assistant Speakers,Electro...</td>\n",
       "      <td>Electronics,Hardware</td>\n",
       "      <td>2017-12-20T00:00:00.000Z</td>\n",
       "      <td>Just an average Alexa option. Does show a few ...</td>\n",
       "      <td>Average</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fire HD 10 Tablet, 10.1 HD Display, Wi-Fi, 16 ...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>eBook Readers,Fire Tablets,Electronics Feature...</td>\n",
       "      <td>Office Supplies,Electronics</td>\n",
       "      <td>2017-08-04T00:00:00.000Z</td>\n",
       "      <td>very good product. Exactly what I wanted, and ...</td>\n",
       "      <td>Greattttttt</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brand New Amazon Kindle Fire 16gb 7\" Ips Displ...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Computers/Tablets &amp; Networking,Tablets &amp; eBook...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>2017-01-23T00:00:00.000Z</td>\n",
       "      <td>This is the 3rd one I've purchased. I've bough...</td>\n",
       "      <td>Very durable!</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name   brand  \\\n",
       "0  All-New Fire HD 8 Tablet, 8\" HD Display, Wi-Fi...  Amazon   \n",
       "1        Amazon - Echo Plus w/ Built-In Hub - Silver  Amazon   \n",
       "2  Amazon Echo Show Alexa-enabled Bluetooth Speak...  Amazon   \n",
       "3  Fire HD 10 Tablet, 10.1 HD Display, Wi-Fi, 16 ...  Amazon   \n",
       "4  Brand New Amazon Kindle Fire 16gb 7\" Ips Displ...  Amazon   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
       "1  Amazon Echo,Smart Home,Networking,Home & Tools...   \n",
       "2  Amazon Echo,Virtual Assistant Speakers,Electro...   \n",
       "3  eBook Readers,Fire Tablets,Electronics Feature...   \n",
       "4  Computers/Tablets & Networking,Tablets & eBook...   \n",
       "\n",
       "             primaryCategories              reviews.date  \\\n",
       "0                  Electronics  2016-12-26T00:00:00.000Z   \n",
       "1         Electronics,Hardware  2018-01-17T00:00:00.000Z   \n",
       "2         Electronics,Hardware  2017-12-20T00:00:00.000Z   \n",
       "3  Office Supplies,Electronics  2017-08-04T00:00:00.000Z   \n",
       "4                  Electronics  2017-01-23T00:00:00.000Z   \n",
       "\n",
       "                                        reviews.text  \\\n",
       "0  Purchased on Black FridayPros - Great Price (e...   \n",
       "1  I purchased two Amazon in Echo Plus and two do...   \n",
       "2  Just an average Alexa option. Does show a few ...   \n",
       "3  very good product. Exactly what I wanted, and ...   \n",
       "4  This is the 3rd one I've purchased. I've bough...   \n",
       "\n",
       "              reviews.title sentiment  \n",
       "0           Powerful tablet  Positive  \n",
       "1  Amazon Echo Plus AWESOME  Positive  \n",
       "2                   Average   Neutral  \n",
       "3               Greattttttt  Positive  \n",
       "4             Very durable!  Positive  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "# train\n",
    "import pandas as pd\n",
    "train_data = pd.read_csv('data/train_data.csv')\n",
    "\n",
    "# test\n",
    "test_data = pd.read_csv('data/test_data_hidden.csv')\n",
    "\n",
    "print(train_data.shape, test_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5cc4a590-5d1a-496e-a61e-8060cca4287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a147c94-989e-40dc-b685-b0db9b28f9c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    3749\n",
       "Neutral      158\n",
       "Negative      93\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking class count data weight\n",
    "train_data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c652d9b-e9e2-4107-a544-c5dd8af2bde2",
   "metadata": {},
   "source": [
    "We have a class imbalance that favors the Positive sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0aecf7f8-a55c-4628-8b19-e2b73766bf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/LNonyane/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# text clean up\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "#words = set(nltk.corpus.words.words())\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c990f582-d35e-464d-b476-1448198b78a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text-cleanup method\n",
    "def cleanup_text(df, column):\n",
    "    df[column].apply(lambda x : ' '.join\\\n",
    "     ([lemmatizer.lemmatize\\\n",
    "      (word.lower()) \\\n",
    "      for word in word_tokenize\\\n",
    "      (re.sub(r'([^\\s\\w]|_)+', ' ',\\\n",
    "       str(x))) if word not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a3825a2-6fa6-4a54-afba-fd302df20452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF vectorizer method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d48bba3b-582c-4bd4-8e1d-12e02c410cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words = stop_words + list(string.printable)\n",
    "\n",
    "# extract tokens from each 'review' of the dataframe using lambda function.\n",
    "# check whether tokens are stop words, lemmatize them and join them side by side using join function.\n",
    "# replace anything other than digits, letters, and white spaces with blank spaces.\n",
    "\n",
    "train_data['cleaned_reviews.text'] = train_data['reviews.text']\\\n",
    ".apply(lambda x : ' '.join\\\n",
    " ([lemmatizer.lemmatize\\\n",
    "  (word.lower()) \\\n",
    "  for word in word_tokenize\\\n",
    "  (re.sub(r'([^\\s\\w]|_)+', ' ',\\\n",
    "   str(x))) if word not in stop_words])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a13079c2-f347-4d8f-aa01-45f889874f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_reviews.text</th>\n",
       "      <th>reviews.text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>purchased black fridaypros great price even sa...</td>\n",
       "      <td>Purchased on Black FridayPros - Great Price (e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>purchased two amazon echo plus two dot plus fo...</td>\n",
       "      <td>I purchased two Amazon in Echo Plus and two do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just average alexa option doe show thing scree...</td>\n",
       "      <td>Just an average Alexa option. Does show a few ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good product exactly wanted good price</td>\n",
       "      <td>very good product. Exactly what I wanted, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this 3rd one purchased bought one niece no cas...</td>\n",
       "      <td>This is the 3rd one I've purchased. I've bough...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                cleaned_reviews.text  \\\n",
       "0  purchased black fridaypros great price even sa...   \n",
       "1  purchased two amazon echo plus two dot plus fo...   \n",
       "2  just average alexa option doe show thing scree...   \n",
       "3             good product exactly wanted good price   \n",
       "4  this 3rd one purchased bought one niece no cas...   \n",
       "\n",
       "                                        reviews.text  \n",
       "0  Purchased on Black FridayPros - Great Price (e...  \n",
       "1  I purchased two Amazon in Echo Plus and two do...  \n",
       "2  Just an average Alexa option. Does show a few ...  \n",
       "3  very good product. Exactly what I wanted, and ...  \n",
       "4  This is the 3rd one I've purchased. I've bough...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[['cleaned_reviews.text', 'reviews.text']].head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "37e0889d-765a-40b5-8ced-7bb2ed686b92",
   "metadata": {},
   "source": [
    "# remove terms with a length of 1\n",
    "train_data['extra_cleaned_reviews.text'] = train_data['cleaned_reviews.text']\\\n",
    ".apply(lambda x : ' '.join\\\n",
    " ([lemmatizer.lemmatize\\\n",
    "  (word.lower()) \\\n",
    "  for word in word_tokenize\\\n",
    "  (re.sub(r'\\b\\w{1}?\\b', ' ',\\\n",
    "   str(x)))]))\n",
    "train_data[['extra_cleaned_reviews.text', 'cleaned_reviews.text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3d5362b-3e07-41b6-9937-8c9d6b80ece4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>11yr</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>...</th>\n",
       "      <th>yr</th>\n",
       "      <th>äôd</th>\n",
       "      <th>äôll</th>\n",
       "      <th>äôm</th>\n",
       "      <th>äôre</th>\n",
       "      <th>äôs</th>\n",
       "      <th>äôt</th>\n",
       "      <th>äôve</th>\n",
       "      <th>äù</th>\n",
       "      <th>äúalexa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.131346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00   10  100   11  11yr   12   13   14       15   16  ...   yr  äôd  äôll  \\\n",
       "0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.22441  0.0  ...  0.0  0.0   0.0   \n",
       "1  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0   0.0   \n",
       "2  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0   0.0   \n",
       "3  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0   0.0   \n",
       "4  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.00000  0.0  ...  0.0  0.0   0.0   \n",
       "\n",
       "        äôm  äôre       äôs  äôt  äôve   äù  äúalexa  \n",
       "0  0.000000   0.0  0.000000  0.0   0.0  0.0      0.0  \n",
       "1  0.131346   0.0  0.111477  0.0   0.0  0.0      0.0  \n",
       "2  0.000000   0.0  0.000000  0.0   0.0  0.0      0.0  \n",
       "3  0.000000   0.0  0.000000  0.0   0.0  0.0      0.0  \n",
       "4  0.000000   0.0  0.000000  0.0   0.0  0.0      0.0  \n",
       "\n",
       "[5 rows x 2000 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDF vectorizer with 5000 max features\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_model = TfidfVectorizer(max_features=2000) # Test set max is 2513.\n",
    "tfidf_df = pd.DataFrame(tfidf_model.fit_transform(train_data['cleaned_reviews.text']).todense()) # todense() creates matrix\n",
    "tfidf_df.columns = sorted(tfidf_model.vocabulary_)\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c47f662-0523-44fd-9d65-f711952a9303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean test data reviews.text\n",
    "test_data['cleaned_reviews.text'] = test_data['reviews.text']\\\n",
    ".apply(lambda x : ' '.join\\\n",
    " ([lemmatizer.lemmatize\\\n",
    "  (word.lower()) \\\n",
    "  for word in word_tokenize\\\n",
    "  (re.sub(r'([^\\s\\w]|_)+', ' ',\\\n",
    "   str(x))) if word not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d246ba19-e1fa-4069-a1b2-2d5622d285b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>105</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>128</th>\n",
       "      <th>128gb</th>\n",
       "      <th>139</th>\n",
       "      <th>15</th>\n",
       "      <th>...</th>\n",
       "      <th>äôll</th>\n",
       "      <th>äôm</th>\n",
       "      <th>äôre</th>\n",
       "      <th>äôs</th>\n",
       "      <th>äôt</th>\n",
       "      <th>äôve</th>\n",
       "      <th>äù</th>\n",
       "      <th>äùcrestron</th>\n",
       "      <th>äú</th>\n",
       "      <th>äúalexa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00   10  100  105   11   12  128  128gb  139   15  ...  äôll  äôm  äôre  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  0.0  ...   0.0  0.0   0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  0.0  ...   0.0  0.0   0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  0.0  ...   0.0  0.0   0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  0.0  ...   0.0  0.0   0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  0.0  ...   0.0  0.0   0.0   \n",
       "\n",
       "   äôs  äôt  äôve   äù  äùcrestron   äú  äúalexa  \n",
       "0  0.0  0.0   0.0  0.0         0.0  0.0      0.0  \n",
       "1  0.0  0.0   0.0  0.0         0.0  0.0      0.0  \n",
       "2  0.0  0.0   0.0  0.0         0.0  0.0      0.0  \n",
       "3  0.0  0.0   0.0  0.0         0.0  0.0      0.0  \n",
       "4  0.0  0.0   0.0  0.0         0.0  0.0      0.0  \n",
       "\n",
       "[5 rows x 2000 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDF vectorizer with 5000 max features for test set\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#tfidf_model = TfidfVectorizer(max_features=2000) # Test set max is 2513.\n",
    "tfidf_df_test = pd.DataFrame(tfidf_model.fit_transform(test_data['cleaned_reviews.text']).todense()) # todense() creates matrix\n",
    "tfidf_df_test.columns = sorted(tfidf_model.vocabulary_)\n",
    "tfidf_df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34c0145-bff4-49d1-8036-e85f977930d7",
   "metadata": {},
   "source": [
    "TFIDF representation of cleaned up 'reviews.text'."
   ]
  },
  {
   "cell_type": "raw",
   "id": "50ba27f6-c56a-4547-8de0-f1e67a19b58a",
   "metadata": {},
   "source": [
    "test_data['clean_reviews.text'] = cleanup_text(test_data, 'reviews.text')\n",
    "test_data['clean_reviews.text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a18e2c0-1a97-41f1-817b-a37d034bdd9b",
   "metadata": {},
   "source": [
    "###### Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "445d1b76-1f7b-4e12-9f32-00963fd06600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and validation sets.\n",
    "X_train = tfidf_df # independent variables\n",
    "y_train = train_data['sentiment'] # labels\n",
    "X_valid = tfidf_df_test # independent variables for test\n",
    "y_valid = test_data['sentiment'] # labels"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bbfa564d-35bb-4477-a069-596f7bb0e240",
   "metadata": {},
   "source": [
    "# training and validation sets from train_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split\\\n",
    "                                     (tfidf_df, train_data['sentiment'],\\\n",
    "                                      test_size=0.2, \\\n",
    "                                      random_state=42, \\\n",
    "                                      stratify=train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "372796f5-4fd2-4728-92db-e881cbd73591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4000, 2000), (4000,), (1000, 2000), (1000,))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5bbdda81-6307-451d-bbd9-dbde2c037897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    3749\n",
       "Neutral      158\n",
       "Negative      93\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3afe8913-804e-4823-bd32-be862a8b46a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize labes in order to use ROC curve to plot multi-class.\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from itertools import cycle\n",
    "\n",
    "y_train_bin = label_binarize(y_train, classes=['Positive', 'Neutral', 'Negative'])\n",
    "n_classes = 3\n",
    "\n",
    "y_valid_bin = label_binarize(y_valid, classes=['Positive', 'Neutral', 'Negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5e19e7f8-6ddf-49a2-a8d7-769c48b4c1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier method\n",
    "def clf_model(model_type, X_train, y_train, X_valid):\n",
    "    model = model_type.fit(X_train, y_train)\n",
    "    predicted_labels = model.predict(X_valid)\n",
    "    predicted_probab = model.predict_proba(X_valid)[:,1]\n",
    "    return [predicted_labels, predicted_probab, model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac1279c7-8cea-46d5-9001-99386dda068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation method\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics import precision_recall_curve, auc, roc_curve\n",
    "def model_evaluation(actual_values, predicted_values, predicted_probabilities):\n",
    "    # confusion matrix\n",
    "    cfn_mat = confusion_matrix(actual_values, predicted_values)\n",
    "    print(\"confusion matrix:\",cfn_mat)\n",
    "    print(\"\\naccuracy:\",accuracy_score(actual_values, predicted_values))\n",
    "    print(\"\\nclassification report:\",classification_report(actual_values, predicted_values))\n",
    "    # Multi class roc curve\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    lw=2\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_valid_bin[:, i], predicted_values[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        colors = cycle(['blue', 'red', 'green'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                 label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                 ''.format(i, roc_auc[i]))\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "    plt.xlim([-0.05, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic for multi-class data')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "    fpr,tpr,threshold = roc_curve(actual_values,predicted_probabilities)\n",
    "    print(\"\\nArea under ROC curve for validation set:\",auc(fpr,tpr))\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    ax.plot(fpr,tpr,label='Validation set AUC')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    ax.legend(loc='best')\n",
    "    plt.show()\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "3fe5c468-00cc-4e45-b00b-6b6adc5feb32",
   "metadata": {},
   "source": [
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "lw=2\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_valid_bin[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "colors = cycle(['blue', 'red', 'green'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic for multi-class data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "73e6c6fe-cbad-473f-96eb-c0a794a52275",
   "metadata": {},
   "source": [
    "def model_evaluation_mnb(actual_values, predicted_values, predicted_probabilities):\n",
    "    # confusion matrix\n",
    "    cfn_mat = confusion_matrix(actual_values, predicted_values)\n",
    "    print(\"confusion matrix:\",cfn_mat)\n",
    "    print(\"\\naccuracy:\",accuracy_score(actual_values, predicted_values))\n",
    "    print(\"\\nclassification report:\",classification_report(actual_values, predicted_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81505146-d0b3-43f0-b200-8fbcdead3683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "389f9ced-c4c4-4527-b67b-f9c333cf7c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  MultinomialNB model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = OneVsRestClassifier(MultinomialNB())\n",
    "multinomialNB_results = clf_model(clf, X_train, y_train, X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "37b301c6-2ee1-4501-8f73-1e87955118c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[  0   3  21]\n",
      " [  0   5  34]\n",
      " [ 14  78 845]]\n",
      "\n",
      "accuracy: 0.85\n",
      "\n",
      "classification report:               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.00      0.00      0.00        24\n",
      "     Neutral       0.06      0.13      0.08        39\n",
      "    Positive       0.94      0.90      0.92       937\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.33      0.34      0.33      1000\n",
      "weighted avg       0.88      0.85      0.87      1000\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [55]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# model evaluation\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# actual values, pred values, pred probab\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultinomialNB_results\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultinomialNB_results\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [47]\u001b[0m, in \u001b[0;36mmodel_evaluation\u001b[0;34m(actual_values, predicted_values, predicted_probabilities)\u001b[0m\n\u001b[1;32m     14\u001b[0m lw\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_classes):\n\u001b[0;32m---> 16\u001b[0m     fpr[i], tpr[i], _ \u001b[38;5;241m=\u001b[39m roc_curve(y_valid_bin[:, i], \u001b[43mpredicted_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     17\u001b[0m     roc_auc[i] \u001b[38;5;241m=\u001b[39m auc(fpr[i], tpr[i])\n\u001b[1;32m     18\u001b[0m     colors \u001b[38;5;241m=\u001b[39m cycle([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "# actual values, pred values, pred probab\n",
    "model_evaluation(y_valid, multinomialNB_results[0], multinomialNB_results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60c89f3-df81-4497-b363-676a51be230f",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Tackling Class Imbalance Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508a7cc8-58db-471d-9ca0-52f339be04b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
